{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# üîê Autoencoder - Detecci√≥n de Anomal√≠as y Reducci√≥n Dimensional\n",
                "## Red Neuronal para Comprimir y Detectar Patrones At√≠picos\n",
                "\n",
                "---\n",
                "\n",
                "### Objetivos:\n",
                "1. Construir Autoencoder para reducci√≥n dimensional\n",
                "2. Detectar anomal√≠as mediante reconstruction error\n",
                "3. Visualizar espacio latente con t-SNE\n",
                "4. Identificar delitos at√≠picos\n",
                "\n",
                "**Autor**: Adonnay Bazaldua  \n",
                "**Fecha**: Noviembre 2025"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, models\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import pickle\n",
                "from sklearn.manifold import TSNE\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cargar datos\n",
                "X_train = np.load('processed_data/X_train.npy')\n",
                "X_test = np.load('processed_data/X_test.npy')\n",
                "\n",
                "with open('processed_data/metadata.pkl', 'rb') as f:\n",
                "    metadata = pickle.load(f)\n",
                "\n",
                "input_dim = X_train.shape[1]\n",
                "print(f\"‚úÖ Datos cargados: {X_train.shape}, features: {input_dim}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "build",
            "metadata": {},
            "source": [
                "## Construcci√≥n del Autoencoder\n",
                "\n",
                "### Arquitectura:\n",
                "```\n",
                "Encoder:  Input(features) ‚Üí Dense(128) ‚Üí Dense(64) ‚Üí Dense(32) [latent]\n",
                "Decoder:  Dense(32) ‚Üí Dense(64) ‚Üí Dense(128) ‚Üí Dense(features)\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "create",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encoder\n",
                "encoder_input = layers.Input(shape=(input_dim,))\n",
                "encoded = layers.Dense(128, activation='relu')(encoder_input)\n",
                "encoded = layers.Dense(64, activation='relu')(encoded)\n",
                "latent = layers.Dense(32, activation='relu', name='latent_space')(encoded)\n",
                "\n",
                "encoder = models.Model(encoder_input, latent, name='encoder')\n",
                "\n",
                "# Decoder\n",
                "decoder_input = layers.Input(shape=(32,))\n",
                "decoded = layers.Dense(64, activation='relu')(decoder_input)\n",
                "decoded = layers.Dense(128, activation='relu')(decoded)\n",
                "decoder_output = layers.Dense(input_dim, activation='linear')(decoded)\n",
                "\n",
                "decoder = models.Model(decoder_input, decoder_output, name='decoder')\n",
                "\n",
                "# Autoencoder completo\n",
                "autoencoder_input = layers.Input(shape=(input_dim,))\n",
                "encoded_out = encoder(autoencoder_input)\n",
                "decoded_out = decoder(encoded_out)\n",
                "\n",
                "autoencoder = models.Model(autoencoder_input, decoded_out, name='autoencoder')\n",
                "\n",
                "autoencoder.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
                "\n",
                "print(\"\\nüìä Encoder:\")\n",
                "encoder.summary()\n",
                "print(\"\\nüìä Decoder:\")\n",
                "decoder.summary()\n",
                "print(f\"\\nüìä Autoencoder completo: {autoencoder.count_params():,} par√°metros\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenar (entrada = salida deseada)\n",
                "print(\"üöÄ Entrenando Autoencoder...\\n\")\n",
                "\n",
                "history = autoencoder.fit(\n",
                "    X_train, X_train,  # Input = Output\n",
                "    epochs=50,\n",
                "    batch_size=256,\n",
                "    validation_split=0.2,\n",
                "    callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)],\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Entrenamiento completado\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "anomalies",
            "metadata": {},
            "source": [
                "## Detecci√≥n de Anomal√≠as\n",
                "\n",
                "Delitos con alto reconstruction error son \"an√≥malos\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "detect",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reconstruir test set\n",
                "X_test_reconstructed = autoencoder.predict(X_test, verbose=0)\n",
                "\n",
                "# Calcular reconstruction error (MSE por muestra)\n",
                "reconstruction_error = np.mean(np.square(X_test - X_test_reconstructed), axis=1)\n",
                "\n",
                "# Definir threshold: media + 2*std\n",
                "threshold = reconstruction_error.mean() + 2 * reconstruction_error.std()\n",
                "\n",
                "anomalies = reconstruction_error > threshold\n",
                "num_anomalies = anomalies.sum()\n",
                "\n",
                "print(f\"\\nüîç Detecci√≥n de Anomal√≠as:\")\n",
                "print(f\"   Threshold: {threshold:.6f}\")\n",
                "print(f\"   Anomal√≠as detectadas: {num_anomalies} ({num_anomalies/len(X_test)*100:.2f}%)\")\n",
                "\n",
                "# Visualizar distribuci√≥n de errores\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.hist(reconstruction_error, bins=50, edgecolor='black', alpha=0.7)\n",
                "plt.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold: {threshold:.4f}')\n",
                "plt.xlabel('Reconstruction Error (MSE)')\n",
                "plt.ylabel('Frecuencia')\n",
                "plt.title('Distribuci√≥n de Reconstruction Error')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.scatter(range(len(reconstruction_error)), reconstruction_error, \n",
                "            c=anomalies, cmap='coolwarm', s=10, alpha=0.6)\n",
                "plt.axhline(threshold, color='red', linestyle='--', linewidth=2)\n",
                "plt.xlabel('√çndice de Muestra')\n",
                "plt.ylabel('Reconstruction Error')\n",
                "plt.title('Anomal√≠as Detectadas (Rojo)')\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('models/autoencoder_anomalies.png', dpi=300)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "latent",
            "metadata": {},
            "source": [
                "## Visualizaci√≥n del Espacio Latente con t-SNE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "tsne",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Obtener representaci√≥n en espacio latente\n",
                "latent_representation = encoder.predict(X_test[:5000], verbose=0)  # Muestra para velocidad\n",
                "\n",
                "# Aplicar t-SNE para reducir a 2D\n",
                "print(\"üîÑ Aplicando t-SNE (esto puede tardar)...\")\n",
                "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
                "latent_2d = tsne.fit_transform(latent_representation)\n",
                "\n",
                "# Visualizar\n",
                "y_test = np.load('processed_data/y_test.npy')\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], \n",
                "                      c=y_test[:5000], cmap='tab20', s=10, alpha=0.6)\n",
                "plt.colorbar(scatter, label='Clase de Delito')\n",
                "plt.xlabel('t-SNE Dimensi√≥n 1')\n",
                "plt.ylabel('t-SNE Dimensi√≥n 2')\n",
                "plt.title('Visualizaci√≥n del Espacio Latente (32D ‚Üí 2D)', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig('models/autoencoder_tsne.png', dpi=300)\n",
                "plt.show()\n",
                "\n",
                "print(\"‚úÖ Visualizaci√≥n completada\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "save",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Guardar modelos\n",
                "autoencoder.save('models/autoencoder_final.keras')\n",
                "encoder.save('models/encoder.keras')\n",
                "decoder.save('models/decoder.keras')\n",
                "\n",
                "# Guardar resultados\n",
                "with open('models/autoencoder_results.pkl', 'wb') as f:\n",
                "    pickle.dump({\n",
                "        'threshold': threshold,\n",
                "        'num_anomalies': int(num_anomalies),\n",
                "        'anomaly_percentage': float(num_anomalies/len(X_test)*100),\n",
                "        'mean_reconstruction_error': float(reconstruction_error.mean()),\n",
                "        'num_parameters': autoencoder.count_params()\n",
                "    }, f)\n",
                "\n",
                "print(\"\\n‚úÖ Autoencoder guardado\")\n",
                "print(\"\\nüìù Pr√≥ximo paso: An√°lisis comparativo de todos los modelos\")\n",
                "print(\"   ‚Üí Notebook: 07_Comparative_Analysis.ipynb\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}