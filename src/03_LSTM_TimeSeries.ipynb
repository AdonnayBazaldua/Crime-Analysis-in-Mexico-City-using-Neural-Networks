{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# üìà LSTM - Predicci√≥n de Series Temporales de Delitos\n",
                "## Long Short-Term Memory para An√°lisis Temporal\n",
                "\n",
                "---\n",
                "\n",
                "### Objetivos:\n",
                "1. Preparar secuencias temporales de delitos\n",
                "2. Construir modelo LSTM para predicci√≥n\n",
                "3. Entrenar y validar el modelo\n",
                "4. Predecir tendencias futuras\n",
                "5. Evaluar con m√©tricas de regresi√≥n (MAE, RMSE, MAPE)\n",
                "\n",
                "**Autor**: Adonnay Bazaldua  \n",
                "**Fecha**: Noviembre 2025"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "imports",
            "metadata": {},
            "source": [
                "## 1. Importaci√≥n de Librer√≠as"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "import_libs",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Deep Learning\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, models, callbacks\n",
                "\n",
                "# Procesamiento de datos\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import pickle\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# M√©tricas\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "\n",
                "# Visualizaci√≥n\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import plotly.graph_objects as go\n",
                "from plotly.subplots import make_subplots\n",
                "\n",
                "# Utils\n",
                "import os\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set random seeds\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
                "print(f\"‚úÖ GPU disponible: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load_data",
            "metadata": {},
            "source": [
                "## 2. Carga de Datos de Series Temporales"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üìÇ Cargando datos de series temporales...\\n\")\n",
                "\n",
                "# Cargar datos agregados por d√≠a\n",
                "df_timeseries = pd.read_csv('processed_data/timeseries_data.csv')\n",
                "df_timeseries['fecha'] = pd.to_datetime(df_timeseries['fecha'])\n",
                "df_timeseries = df_timeseries.sort_values('fecha').reset_index(drop=True)\n",
                "\n",
                "print(f\"‚úÖ Datos cargados:\")\n",
                "print(f\"   Per√≠odo: {df_timeseries['fecha'].min()} a {df_timeseries['fecha'].max()}\")\n",
                "print(f\"   Total de d√≠as: {len(df_timeseries)}\")\n",
                "print(f\"   Features: {len(df_timeseries.columns) - 1} (excluyendo fecha)\")\n",
                "\n",
                "print(f\"\\nüìä Estad√≠sticas de delitos totales por d√≠a:\")\n",
                "print(df_timeseries['total_delitos'].describe())\n",
                "\n",
                "# Mostrar primeras filas\n",
                "print(f\"\\nüîç Primeras 5 filas:\")\n",
                "print(df_timeseries.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "visualize",
            "metadata": {},
            "source": [
                "## 3. Visualizaci√≥n de la Serie Temporal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "plot_series",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizaci√≥n interactiva con Plotly\n",
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=df_timeseries['fecha'],\n",
                "    y=df_timeseries['total_delitos'],\n",
                "    mode='lines',\n",
                "    name='Total Delitos',\n",
                "    line=dict(color='steelblue', width=1.5)\n",
                "))\n",
                "\n",
                "# Media m√≥vil de 30 d√≠as\n",
                "df_timeseries['ma_30'] = df_timeseries['total_delitos'].rolling(window=30).mean()\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=df_timeseries['fecha'],\n",
                "    y=df_timeseries['ma_30'],\n",
                "    mode='lines',\n",
                "    name='Media M√≥vil 30 d√≠as',\n",
                "    line=dict(color='coral', width=2, dash='dash')\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title='Serie Temporal de Delitos en CDMX (2016-2024)',\n",
                "    xaxis_title='Fecha',\n",
                "    yaxis_title='N√∫mero de Delitos por D√≠a',\n",
                "    hovermode='x unified',\n",
                "    height=500\n",
                ")\n",
                "\n",
                "fig.show()\n",
                "\n",
                "# Tambi√©n con matplotlib para guardar\n",
                "fig_static, ax = plt.subplots(figsize=(16, 6))\n",
                "ax.plot(df_timeseries['fecha'], df_timeseries['total_delitos'], \n",
                "        linewidth=1, alpha=0.7, label='Total Delitos')\n",
                "ax.plot(df_timeseries['fecha'], df_timeseries['ma_30'], \n",
                "        linewidth=2, color='red', label='Media M√≥vil 30d')\n",
                "ax.set_xlabel('Fecha')\n",
                "ax.set_ylabel('Total de Delitos')\n",
                "ax.set_title('Serie Temporal de Delitos en CDMX', fontsize=14, fontweight='bold')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "plt.xticks(rotation=45)\n",
                "plt.tight_layout()\n",
                "plt.savefig('models/lstm_timeseries_overview.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"‚úÖ Visualizaci√≥n guardada en 'models/lstm_timeseries_overview.png'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "prepare_sequences",
            "metadata": {},
            "source": [
                "## 4. Preparaci√≥n de Secuencias para LSTM\n",
                "\n",
                "LSTM requiere datos en formato de secuencias: usaremos ventanas de 30 d√≠as para predecir el d√≠a siguiente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "create_sequences",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_sequences(data, seq_length):\n",
                "    \"\"\"\n",
                "    Crea secuencias de entrenamiento para LSTM.\n",
                "    \n",
                "    Args:\n",
                "        data: Array de datos temporales\n",
                "        seq_length: Longitud de la secuencia (ventana temporal)\n",
                "    \n",
                "    Returns:\n",
                "        X: Secuencias de entrada (samples, seq_length, features)\n",
                "        y: Valores objetivo (samples,)\n",
                "    \"\"\"\n",
                "    X, y = [], []\n",
                "    \n",
                "    for i in range(len(data) - seq_length):\n",
                "        X.append(data[i:i + seq_length])\n",
                "        y.append(data[i + seq_length])\n",
                "    \n",
                "    return np.array(X), np.array(y)\n",
                "\n",
                "print(\"üîß Preparando secuencias para LSTM...\\n\")\n",
                "\n",
                "# Usar solo la columna de total_delitos para simplificar\n",
                "# (Se puede expandir a m√∫ltiples features despu√©s)\n",
                "data = df_timeseries['total_delitos'].values.reshape(-1, 1)\n",
                "\n",
                "# Normalizar datos (LSTM funciona mejor con datos normalizados)\n",
                "scaler_lstm = MinMaxScaler(feature_range=(0, 1))\n",
                "data_scaled = scaler_lstm.fit_transform(data)\n",
                "\n",
                "# Par√°metros\n",
                "SEQ_LENGTH = 30  # Usar 30 d√≠as anteriores\n",
                "\n",
                "# Crear secuencias\n",
                "X_seq, y_seq = create_sequences(data_scaled, SEQ_LENGTH)\n",
                "\n",
                "print(f\"‚úÖ Secuencias creadas:\")\n",
                "print(f\"   Shape X: {X_seq.shape}  # (samples, timesteps, features)\")\n",
                "print(f\"   Shape y: {y_seq.shape}  # (samples,)\")\n",
                "print(f\"   Timesteps: {SEQ_LENGTH} d√≠as\")\n",
                "\n",
                "# Divisi√≥n train/val/test: 70%, 15%, 15%\n",
                "train_size = int(0.70 * len(X_seq))\n",
                "val_size = int(0.15 * len(X_seq))\n",
                "\n",
                "X_train_lstm = X_seq[:train_size]\n",
                "y_train_lstm = y_seq[:train_size]\n",
                "\n",
                "X_val_lstm = X_seq[train_size:train_size + val_size]\n",
                "y_val_lstm = y_seq[train_size:train_size + val_size]\n",
                "\n",
                "X_test_lstm = X_seq[train_size + val_size:]\n",
                "y_test_lstm = y_seq[train_size + val_size:]\n",
                "\n",
                "print(f\"\\nüìä Divisi√≥n de datos:\")\n",
                "print(f\"   Train: {X_train_lstm.shape[0]} secuencias ({X_train_lstm.shape[0]/len(X_seq)*100:.1f}%)\")\n",
                "print(f\"   Val:   {X_val_lstm.shape[0]} secuencias ({X_val_lstm.shape[0]/len(X_seq)*100:.1f}%)\")\n",
                "print(f\"   Test:  {X_test_lstm.shape[0]} secuencias ({X_test_lstm.shape[0]/len(X_seq)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "build_model",
            "metadata": {},
            "source": [
                "## 5. Construcci√≥n del Modelo LSTM\n",
                "\n",
                "### Arquitectura:\n",
                "```\n",
                "Input(30, 1)  # 30 timesteps, 1 feature\n",
                "  ‚Üí LSTM(128, return_sequences=True) ‚Üí Dropout(0.2)\n",
                "  ‚Üí LSTM(64) ‚Üí Dropout(0.2)\n",
                "  ‚Üí Dense(32, activation='relu')\n",
                "  ‚Üí Dense(1, activation='linear')  # Predicci√≥n de conteo\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "create_lstm",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_lstm_model(seq_length, n_features, learning_rate=0.001):\n",
                "    \"\"\"\n",
                "    Crea modelo LSTM para predicci√≥n de series temporales.\n",
                "    \n",
                "    Args:\n",
                "        seq_length: Longitud de la secuencia de entrada\n",
                "        n_features: N√∫mero de features\n",
                "        learning_rate: Tasa de aprendizaje\n",
                "    \n",
                "    Returns:\n",
                "        Modelo LSTM compilado\n",
                "    \"\"\"\n",
                "    model = models.Sequential([\n",
                "        # Input layer\n",
                "        layers.Input(shape=(seq_length, n_features)),\n",
                "        \n",
                "        # Primera capa LSTM (con return_sequences=True para apilar)\n",
                "        layers.LSTM(128, return_sequences=True, activation='tanh'),\n",
                "        layers.Dropout(0.2),\n",
                "        \n",
                "        # Segunda capa LSTM\n",
                "        layers.LSTM(64, activation='tanh'),\n",
                "        layers.Dropout(0.2),\n",
                "        \n",
                "        # Capa densa\n",
                "        layers.Dense(32, activation='relu'),\n",
                "        \n",
                "        # Capa de salida (regresi√≥n)\n",
                "        layers.Dense(1, activation='linear')\n",
                "    ], name='LSTM_Crime_Predictor')\n",
                "    \n",
                "    # Compilar\n",
                "    model.compile(\n",
                "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
                "        loss='mse',  # Mean Squared Error para regresi√≥n\n",
                "        metrics=['mae', 'mse']\n",
                "    )\n",
                "    \n",
                "    return model\n",
                "\n",
                "# Crear modelo\n",
                "print(\"üèóÔ∏è Construyendo modelo LSTM...\\n\")\n",
                "lstm_model = create_lstm_model(seq_length=SEQ_LENGTH, n_features=1)\n",
                "\n",
                "# Resumen\n",
                "lstm_model.summary()\n",
                "\n",
                "# Contar par√°metros\n",
                "total_params = lstm_model.count_params()\n",
                "print(f\"\\nüìä Total de par√°metros: {total_params:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "callbacks",
            "metadata": {},
            "source": [
                "## 6. Configuraci√≥n de Callbacks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup_callbacks",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Callbacks\n",
                "early_stopping = callbacks.EarlyStopping(\n",
                "    monitor='val_loss',\n",
                "    patience=15,\n",
                "    restore_best_weights=True,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "reduce_lr = callbacks.ReduceLROnPlateau(\n",
                "    monitor='val_loss',\n",
                "    factor=0.5,\n",
                "    patience=7,\n",
                "    min_lr=1e-7,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "model_checkpoint = callbacks.ModelCheckpoint(\n",
                "    'models/lstm_best.keras',\n",
                "    monitor='val_mae',\n",
                "    save_best_only=True,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "tensorboard_callback = callbacks.TensorBoard(\n",
                "    log_dir='logs/lstm',\n",
                "    histogram_freq=1\n",
                ")\n",
                "\n",
                "callbacks_list = [early_stopping, reduce_lr, model_checkpoint, tensorboard_callback]\n",
                "\n",
                "print(\"‚úÖ Callbacks configurados\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "training",
            "metadata": {},
            "source": [
                "## 7. Entrenamiento del Modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üöÄ Iniciando entrenamiento LSTM...\\n\")\n",
                "\n",
                "# Par√°metros\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 100\n",
                "\n",
                "# Entrenar\n",
                "history_lstm = lstm_model.fit(\n",
                "    X_train_lstm, y_train_lstm,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    epochs=EPOCHS,\n",
                "    validation_data=(X_val_lstm, y_val_lstm),\n",
                "    callbacks=callbacks_list,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Entrenamiento completado!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "training_curves",
            "metadata": {},
            "source": [
                "## 8. Visualizaci√≥n de Curvas de Entrenamiento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "plot_training",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
                "\n",
                "# Loss (MSE)\n",
                "axes[0].plot(history_lstm.history['loss'], label='Train Loss (MSE)', linewidth=2)\n",
                "axes[0].plot(history_lstm.history['val_loss'], label='Val Loss (MSE)', linewidth=2)\n",
                "axes[0].set_xlabel('√âpoca')\n",
                "axes[0].set_ylabel('Loss (MSE)')\n",
                "axes[0].set_title('Curva de P√©rdida - LSTM')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# MAE\n",
                "axes[1].plot(history_lstm.history['mae'], label='Train MAE', linewidth=2)\n",
                "axes[1].plot(history_lstm.history['val_mae'], label='Val MAE', linewidth=2)\n",
                "axes[1].set_xlabel('√âpoca')\n",
                "axes[1].set_ylabel('MAE')\n",
                "axes[1].set_title('Error Absoluto Medio - LSTM')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('models/lstm_training_curves.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"‚úÖ Curvas guardadas en 'models/lstm_training_curves.png'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "evaluation",
            "metadata": {},
            "source": [
                "## 9. Evaluaci√≥n y Predicciones"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "evaluate",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üìä Evaluando modelo LSTM en conjunto de prueba...\\n\")\n",
                "\n",
                "# Predicciones\n",
                "y_pred_train = lstm_model.predict(X_train_lstm, verbose=0)\n",
                "y_pred_val = lstm_model.predict(X_val_lstm, verbose=0)\n",
                "y_pred_test = lstm_model.predict(X_test_lstm, verbose=0)\n",
                "\n",
                "# Desnormalizar predicciones\n",
                "y_pred_train_inv = scaler_lstm.inverse_transform(y_pred_train)\n",
                "y_pred_val_inv = scaler_lstm.inverse_transform(y_pred_val)\n",
                "y_pred_test_inv = scaler_lstm.inverse_transform(y_pred_test)\n",
                "\n",
                "y_train_lstm_inv = scaler_lstm.inverse_transform(y_train_lstm.reshape(-1, 1))\n",
                "y_val_lstm_inv = scaler_lstm.inverse_transform(y_val_lstm.reshape(-1, 1))\n",
                "y_test_lstm_inv = scaler_lstm.inverse_transform(y_test_lstm.reshape(-1, 1))\n",
                "\n",
                "# Calcular m√©tricas\n",
                "def calculate_metrics(y_true, y_pred):\n",
                "    mae = mean_absolute_error(y_true, y_pred)\n",
                "    mse = mean_squared_error(y_true, y_pred)\n",
                "    rmse = np.sqrt(mse)\n",
                "    r2 = r2_score(y_true, y_pred)\n",
                "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
                "    return mae, rmse, r2, mape\n",
                "\n",
                "# M√©tricas para cada conjunto\n",
                "train_metrics = calculate_metrics(y_train_lstm_inv, y_pred_train_inv)\n",
                "val_metrics = calculate_metrics(y_val_lstm_inv, y_pred_val_inv)\n",
                "test_metrics = calculate_metrics(y_test_lstm_inv, y_pred_test_inv)\n",
                "\n",
                "print(\"üéØ M√©tricas de Rendimiento:\\n\")\n",
                "print(f\"{'Conjunto':<12} {'MAE':<12} {'RMSE':<12} {'R¬≤':<12} {'MAPE (%)':<12}\")\n",
                "print(\"-\" * 60)\n",
                "print(f\"{'Train':<12} {train_metrics[0]:<12.2f} {train_metrics[1]:<12.2f} {train_metrics[2]:<12.4f} {train_metrics[3]:<12.2f}\")\n",
                "print(f\"{'Validation':<12} {val_metrics[0]:<12.2f} {val_metrics[1]:<12.2f} {val_metrics[2]:<12.4f} {val_metrics[3]:<12.2f}\")\n",
                "print(f\"{'Test':<12} {test_metrics[0]:<12.2f} {test_metrics[1]:<12.2f} {test_metrics[2]:<12.4f} {test_metrics[3]:<12.2f}\")\n",
                "\n",
                "print(f\"\\nüìà Interpretaci√≥n:\")\n",
                "print(f\"   MAE (Mean Absolute Error): Error promedio de {test_metrics[0]:.0f} delitos por d√≠a\")\n",
                "print(f\"   RMSE (Root Mean Squared Error): {test_metrics[1]:.0f} delitos\")\n",
                "print(f\"   R¬≤ Score: Explica el {test_metrics[2]*100:.2f}% de la varianza\")\n",
                "print(f\"   MAPE (Mean Absolute Percentage Error): {test_metrics[3]:.2f}% de error porcentual\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "visualize_predictions",
            "metadata": {},
            "source": [
                "## 10. Visualizaci√≥n de Predicciones vs Real"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "plot_predictions",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Crear √≠ndices de tiempo para visualizaci√≥n\n",
                "train_dates = df_timeseries['fecha'].iloc[SEQ_LENGTH:SEQ_LENGTH+len(y_train_lstm)]\n",
                "val_dates = df_timeseries['fecha'].iloc[SEQ_LENGTH+len(y_train_lstm):SEQ_LENGTH+len(y_train_lstm)+len(y_val_lstm)]\n",
                "test_dates = df_timeseries['fecha'].iloc[SEQ_LENGTH+len(y_train_lstm)+len(y_val_lstm):]\n",
                "\n",
                "# Plot completo\n",
                "fig = go.Figure()\n",
                "\n",
                "# Train\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=train_dates,\n",
                "    y=y_train_lstm_inv.flatten(),\n",
                "    mode='lines',\n",
                "    name='Real (Train)',\n",
                "    line=dict(color='lightblue', width=1)\n",
                "))\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=train_dates,\n",
                "    y=y_pred_train_inv.flatten(),\n",
                "    mode='lines',\n",
                "    name='Predicci√≥n (Train)',\n",
                "    line=dict(color='blue', width=1, dash='dot')\n",
                "))\n",
                "\n",
                "# Validation\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=val_dates,\n",
                "    y=y_val_lstm_inv.flatten(),\n",
                "    mode='lines',\n",
                "    name='Real (Val)',\n",
                "    line=dict(color='lightcoral', width=1)\n",
                "))\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=val_dates,\n",
                "    y=y_pred_val_inv.flatten(),\n",
                "    mode='lines',\n",
                "    name='Predicci√≥n (Val)',\n",
                "    line=dict(color='red', width=1, dash='dot')\n",
                "))\n",
                "\n",
                "# Test\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=test_dates,\n",
                "    y=y_test_lstm_inv.flatten(),\n",
                "    mode='lines',\n",
                "    name='Real (Test)',\n",
                "    line=dict(color='lightgreen', width=2)\n",
                "))\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=test_dates,\n",
                "    y=y_pred_test_inv.flatten(),\n",
                "    mode='lines',\n",
                "    name='Predicci√≥n (Test)',\n",
                "    line=dict(color='darkgreen', width=2, dash='dash')\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title='LSTM: Predicciones vs Valores Reales',\n",
                "    xaxis_title='Fecha',\n",
                "    yaxis_title='Total de Delitos por D√≠a',\n",
                "    hovermode='x unified',\n",
                "    height=600\n",
                ")\n",
                "\n",
                "fig.show()\n",
                "\n",
                "# Zoom en conjunto de prueba (matplotlib)\n",
                "fig_test, ax = plt.subplots(figsize=(16, 6))\n",
                "ax.plot(test_dates, y_test_lstm_inv, linewidth=2, label='Real', color='steelblue')\n",
                "ax.plot(test_dates, y_pred_test_inv, linewidth=2, label='Predicci√≥n LSTM', \n",
                "        color='coral', linestyle='--')\n",
                "ax.fill_between(test_dates, y_test_lstm_inv.flatten(), y_pred_test_inv.flatten(), \n",
                "                 alpha=0.2, color='gray')\n",
                "ax.set_xlabel('Fecha')\n",
                "ax.set_ylabel('Total de Delitos')\n",
                "ax.set_title('LSTM - Predicciones en Conjunto de Prueba', fontsize=14, fontweight='bold')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "plt.xticks(rotation=45)\n",
                "plt.tight_layout()\n",
                "plt.savefig('models/lstm_predictions_test.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"‚úÖ Visualizaciones guardadas\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "residuals",
            "metadata": {},
            "source": [
                "## 11. An√°lisis de Residuos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "analyze_residuals",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calcular residuos (errores)\n",
                "residuals_test = y_test_lstm_inv.flatten() - y_pred_test_inv.flatten()\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "# Histograma de residuos\n",
                "axes[0].hist(residuals_test, bins=50, edgecolor='black', alpha=0.7)\n",
                "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
                "axes[0].set_xlabel('Residuos (Real - Predicci√≥n)')\n",
                "axes[0].set_ylabel('Frecuencia')\n",
                "axes[0].set_title('Distribuci√≥n de Residuos')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Scatter plot: Predicciones vs Real\n",
                "axes[1].scatter(y_test_lstm_inv, y_pred_test_inv, alpha=0.5, s=20)\n",
                "axes[1].plot([y_test_lstm_inv.min(), y_test_lstm_inv.max()],\n",
                "             [y_test_lstm_inv.min(), y_test_lstm_inv.max()],\n",
                "             'r--', linewidth=2, label='L√≠nea Ideal')\n",
                "axes[1].set_xlabel('Valores Reales')\n",
                "axes[1].set_ylabel('Predicciones')\n",
                "axes[1].set_title('Predicciones vs Valores Reales')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "# Residuos a lo largo del tiempo\n",
                "axes[2].scatter(range(len(residuals_test)), residuals_test, alpha=0.5, s=20)\n",
                "axes[2].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
                "axes[2].set_xlabel('√çndice de Muestra')\n",
                "axes[2].set_ylabel('Residuos')\n",
                "axes[2].set_title('Residuos a lo Largo del Tiempo')\n",
                "axes[2].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('models/lstm_residuals_analysis.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nüìä Estad√≠sticas de residuos:\")\n",
                "print(f\"   Media: {residuals_test.mean():.2f}\")\n",
                "print(f\"   Std: {residuals_test.std():.2f}\")\n",
                "print(f\"   Min: {residuals_test.min():.2f}\")\n",
                "print(f\"   Max: {residuals_test.max():.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "save",
            "metadata": {},
            "source": [
                "## 12. Guardar Modelo y Resultados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "save_model",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üíæ Guardando modelo y resultados...\\n\")\n",
                "\n",
                "# Guardar modelo\n",
                "lstm_model.save('models/lstm_predictor_final.keras')\n",
                "\n",
                "# Guardar scaler\n",
                "with open('models/lstm_scaler.pkl', 'wb') as f:\n",
                "    pickle.dump(scaler_lstm, f)\n",
                "\n",
                "# Guardar historial\n",
                "with open('models/lstm_history.pkl', 'wb') as f:\n",
                "    pickle.dump(history_lstm.history, f)\n",
                "\n",
                "# Guardar predicciones\n",
                "np.save('models/lstm_predictions_test.npy', y_pred_test_inv)\n",
                "\n",
                "# Guardar resultados\n",
                "results_lstm = {\n",
                "    'test_mae': test_metrics[0],\n",
                "    'test_rmse': test_metrics[1],\n",
                "    'test_r2': test_metrics[2],\n",
                "    'test_mape': test_metrics[3],\n",
                "    'val_mae': val_metrics[0],\n",
                "    'val_rmse': val_metrics[1],\n",
                "    'val_r2': val_metrics[2],\n",
                "    'val_mape': val_metrics[3],\n",
                "    'num_parameters': total_params,\n",
                "    'seq_length': SEQ_LENGTH,\n",
                "    'num_epochs_trained': len(history_lstm.history['loss'])\n",
                "}\n",
                "\n",
                "with open('models/lstm_results.pkl', 'wb') as f:\n",
                "    pickle.dump(results_lstm, f)\n",
                "\n",
                "print(\"‚úÖ Archivos guardados:\")\n",
                "print(\"   - models/lstm_predictor_final.keras\")\n",
                "print(\"   - models/lstm_best.keras\")\n",
                "print(\"   - models/lstm_scaler.pkl\")\n",
                "print(\"   - models/lstm_history.pkl\")\n",
                "print(\"   - models/lstm_predictions_test.npy\")\n",
                "print(\"   - models/lstm_results.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary",
            "metadata": {},
            "source": [
                "## 13. Resumen Final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "final_summary",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*80)\n",
                "print(\" \"*30 + \"RESUMEN LSTM\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "print(f\"\\nüèóÔ∏è ARQUITECTURA:\")\n",
                "print(f\"   Tipo: LSTM (Long Short-Term Memory)\")\n",
                "print(f\"   Capas LSTM: 2 (128 ‚Üí 64 unidades)\")\n",
                "print(f\"   Secuencia de entrada: {SEQ_LENGTH} timesteps\")\n",
                "print(f\"   Par√°metros totales: {total_params:,}\")\n",
                "\n",
                "print(f\"\\nüìä DATOS:\")\n",
                "print(f\"   Total de secuencias: {len(X_seq):,}\")\n",
                "print(f\"   Entrenamiento: {len(X_train_lstm):,}\")\n",
                "print(f\"   Validaci√≥n: {len(X_val_lstm):,}\")\n",
                "print(f\"   Prueba: {len(X_test_lstm):,}\")\n",
                "\n",
                "print(f\"\\nüéØ RENDIMIENTO (Test Set):\")\n",
                "print(f\"   MAE: {test_metrics[0]:.2f} delitos/d√≠a\")\n",
                "print(f\"   RMSE: {test_metrics[1]:.2f} delitos\")\n",
                "print(f\"   R¬≤ Score: {test_metrics[2]:.4f} ({test_metrics[2]*100:.2f}%)\")\n",
                "print(f\"   MAPE: {test_metrics[3]:.2f}%\")\n",
                "print(f\"   √âpocas entrenadas: {len(history_lstm.history['loss'])}\")\n",
                "\n",
                "print(f\"\\n‚úÖ MODELO LSTM COMPLETADO Y GUARDADO\")\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "\n",
                "print(\"\\nüìù Pr√≥ximo paso: Implementar GRU y comparar con LSTM\")\n",
                "print(\"   ‚Üí Notebook: 04_GRU_TimeSeries.ipynb\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}