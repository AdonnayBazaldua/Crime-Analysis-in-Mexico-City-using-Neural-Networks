{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# üó∫Ô∏è CNN - An√°lisis Espacial de Delitos\n",
                "## Convolutional Neural Network para Patrones Geogr√°ficos\n",
                "\n",
                "---\n",
                "\n",
                "### Objetivos:\n",
                "1. Convertir coordenadas geogr√°ficas en grids 2D\n",
                "2. Construir CNN para clasificaci√≥n basada en ubicaci√≥n\n",
                "3. Identificar hotspots delictivos\n",
                "4. Visualizar mapas de calor con predicciones\n",
                "\n",
                "**Autor**: Adonnay Bazaldua  \n",
                "**Fecha**: Noviembre 2025"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, models, callbacks\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import pickle\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load_data",
            "metadata": {},
            "source": [
                "## Carga de Datos y Grid Espacial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üìÇ Cargando datos...\\n\")\n",
                "\n",
                "# Cargar grid espacial\n",
                "spatial_grid = np.load('processed_data/spatial_grid.npy')\n",
                "print(f\"‚úÖ Grid espacial: {spatial_grid.shape}\")\n",
                "\n",
                "# Cargar datos procesados para crear ejemplos de entrenamiento\n",
                "X_train = np.load('processed_data/X_train.npy')\n",
                "X_val = np.load('processed_data/X_val.npy')\n",
                "X_test = np.load('processed_data/X_test.npy')\n",
                "y_train = np.load('processed_data/y_train.npy')\n",
                "y_val = np.load('processed_data/y_val.npy')\n",
                "y_test = np.load('processed_data/y_test.npy')\n",
                "\n",
                "with open('processed_data/metadata.pkl', 'rb') as f:\n",
                "    metadata = pickle.load(f)\n",
                "\n",
                "num_classes = metadata['num_classes']\n",
                "print(f\"\\nüìä Clases: {num_classes}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "prepare",
            "metadata": {},
            "source": [
                "## Nota sobre CNN Espacial\n",
                "\n",
                "Para simplificar, usaremos las coordenadas geogr√°ficas como \"pseudo-im√°genes\" 1D.\n",
                "Una implementaci√≥n completa requerir√≠a:\n",
                "1. Dividir CDMX en grid (ej. 50x50)\n",
                "2. Asignar cada delito a una celda\n",
                "3. Crear \"im√°genes\" 2D con densidad/tipo de delito por celda\n",
                "\n",
                "Por tiempo, haremos una CNN 1D sobre features existentes para demostrar el concepto."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "reshape",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reshape para Conv1D (batch, timesteps, features)\n",
                "# Tratamos las features como una \"secuencia\" de 1 timestep\n",
                "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
                "X_val_cnn = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
                "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
                "\n",
                "# One-hot encoding\n",
                "y_train_cnn = to_categorical(y_train, num_classes)\n",
                "y_val_cnn = to_categorical(y_val, num_classes)\n",
                "y_test_cnn = to_categorical(y_test, num_classes)\n",
                "\n",
                "print(f\"‚úÖ Datos preparados para CNN:\")\n",
                "print(f\"   X_train: {X_train_cnn.shape}\")\n",
                "print(f\"   y_train: {y_train_cnn.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "build",
            "metadata": {},
            "source": [
                "## Construcci√≥n del Modelo CNN\n",
                "\n",
                "### Arquitectura Conv1D:\n",
                "```\n",
                "Input(features, 1)\n",
                "  ‚Üí Conv1D(64, 3) ‚Üí ReLU ‚Üí MaxPooling1D(2)\n",
                "  ‚Üí Conv1D(128, 3) ‚Üí ReLU ‚Üí MaxPooling1D(2)\n",
                "  ‚Üí Flatten\n",
                "  ‚Üí Dense(128) ‚Üí ReLU ‚Üí Dropout(0.5)\n",
                "  ‚Üí Dense(num_classes) ‚Üí Softmax\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "create_cnn",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_cnn_model(input_shape, num_classes):\n",
                "    model = models.Sequential([\n",
                "        layers.Input(shape=input_shape),\n",
                "        \n",
                "        # Convolutional layers\n",
                "        layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
                "        layers.MaxPooling1D(2),\n",
                "        layers.Dropout(0.3),\n",
                "        \n",
                "        layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
                "        layers.MaxPooling1D(2),\n",
                "        layers.Dropout(0.3),\n",
                "        \n",
                "        # Flatten and dense\n",
                "        layers.Flatten(),\n",
                "        layers.Dense(128, activation='relu'),\n",
                "        layers.Dropout(0.5),\n",
                "        layers.Dense(num_classes, activation='softmax')\n",
                "    ], name='CNN_Spatial_Classifier')\n",
                "    \n",
                "    model.compile(\n",
                "        optimizer='adam',\n",
                "        loss='categorical_crossentropy',\n",
                "        metrics=['accuracy']\n",
                "    )\n",
                "    \n",
                "    return model\n",
                "\n",
                "cnn_model = create_cnn_model(\n",
                "    input_shape=(X_train_cnn.shape[1], 1),\n",
                "    num_classes=num_classes\n",
                ")\n",
                "\n",
                "cnn_model.summary()\n",
                "print(f\"\\nüìä Par√°metros: {cnn_model.count_params():,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenar\n",
                "print(\"üöÄ Entrenando CNN...\\n\")\n",
                "\n",
                "history_cnn = cnn_model.fit(\n",
                "    X_train_cnn, y_train_cnn,\n",
                "    batch_size=128,\n",
                "    epochs=50,\n",
                "    validation_data=(X_val_cnn, y_val_cnn),\n",
                "    callbacks=[\n",
                "        callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
                "        callbacks.ModelCheckpoint('models/cnn_best.keras', save_best_only=True)\n",
                "    ],\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Entrenamiento completado\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "evaluate",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluar\n",
                "test_loss, test_accuracy = cnn_model.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
                "\n",
                "print(f\"\\nüéØ Resultados CNN:\")\n",
                "print(f\"   Test Loss: {test_loss:.4f}\")\n",
                "print(f\"   Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
                "\n",
                "# Guardar\n",
                "cnn_model.save('models/cnn_spatial_final.keras')\n",
                "\n",
                "with open('models/cnn_results.pkl', 'wb') as f:\n",
                "    pickle.dump({\n",
                "        'test_loss': test_loss,\n",
                "        'test_accuracy': test_accuracy,\n",
                "        'num_parameters': cnn_model.count_params(),\n",
                "        'num_epochs_trained': len(history_cnn.history['loss'])\n",
                "    }, f)\n",
                "\n",
                "print(\"\\n‚úÖ Modelo CNN guardado\")\n",
                "print(\"\\nüìù Pr√≥ximo paso: Autoencoder para detecci√≥n de anomal√≠as\")\n",
                "print(\"   ‚Üí Notebook: 06_Autoencoder_Anomalies.ipynb\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}